#!/usr/bin/env python3
"""
Declutter MCP - One tool to detect bloat and fix .claudeignore

Design: Jesse Vincent's MCP philosophy
- One flexible tool, not many
- Plain English errors
- Auto-recovery over fail-fast
- Minimal token footprint (~200 tokens)
"""

import os
from pathlib import Path
from fastmcp import FastMCP

mcp = FastMCP("declutter")

# Detection rules: file -> (project_type, patterns_to_ignore)
DETECTORS = {
    "requirements.txt": ("python", [".venv/", "venv/", "__pycache__/", "*.pyc"]),
    "pyproject.toml": ("python", [".venv/", "venv/", "__pycache__/", "*.pyc"]),
    "package.json": ("node", ["node_modules/", ".next/", "dist/", ".turbo/"]),
    "Package.swift": ("swift", [".build/", "DerivedData/", "*.xcarchive", ".swiftpm/"]),
    "Cargo.toml": ("rust", ["target/"]),
    "go.mod": ("go", ["vendor/"]),
}

COMMON_BLOAT = {
    "logs/": "logs",
    "*.log": "logs",
    "*.db": "database",
    "*.db-wal": "database",
    "*.db-shm": "database",
    "*.parquet": "data",
    "htmlcov/": "coverage",
    ".coverage": "coverage",
}


def get_size(path: Path) -> int:
    """Get directory size in bytes."""
    if path.is_file():
        return path.stat().st_size
    total = 0
    try:
        for p in path.rglob("*"):
            if p.is_file():
                total += p.stat().st_size
    except (PermissionError, OSError):
        pass
    return total


def human_size(size: int) -> str:
    """Convert bytes to human readable."""
    for unit in ["B", "KB", "MB", "GB"]:
        if size < 1024:
            return f"{size:.0f}{unit}"
        size /= 1024
    return f"{size:.1f}TB"


def detect_project(path: Path) -> tuple[list[str], set[str]]:
    """Detect project types and collect ignore patterns."""
    types = []
    patterns = set()

    for marker, (ptype, pats) in DETECTORS.items():
        if (path / marker).exists() or list(path.glob(marker)):
            if ptype not in types:
                types.append(ptype)
            patterns.update(pats)

    # Check for common bloat
    for pattern, category in COMMON_BLOAT.items():
        if pattern.startswith("*"):
            if list(path.glob(pattern)):
                patterns.add(pattern)
        elif (path / pattern.rstrip("/")).exists():
            patterns.add(pattern)

    return types, patterns


def find_bloat(path: Path) -> dict[str, int]:
    """Find bloated directories and their sizes."""
    bloat = {}
    candidates = [".venv", "venv", "node_modules", "__pycache__", ".build",
                  "target", ".next", "logs", "htmlcov", "DerivedData"]

    for name in candidates:
        p = path / name
        if p.exists():
            bloat[name] = get_size(p)

    # Large files
    for f in path.rglob("*"):
        if f.is_file() and f.stat().st_size > 50_000_000:  # 50MB
            rel = f.relative_to(path)
            bloat[str(rel)] = f.stat().st_size

    return bloat


def run_declutter(path: str = ".", fix: bool = False) -> str:
    """Core declutter logic - separated for testing."""
    p = Path(path).expanduser().resolve()

    if not p.exists():
        return f"Path not found: {path}. Check the path and try again."

    if not p.is_dir():
        return f"Not a directory: {path}. Point to a project folder."

    # Detect and analyze
    types, patterns = detect_project(p)
    bloat = find_bloat(p)
    total_bloat = sum(bloat.values())
    tokens_wasted = total_bloat // 4  # ~4 bytes per token

    # Check existing .claudeignore
    claudeignore = p / ".claudeignore"
    has_ignore = claudeignore.exists()

    # Build report
    lines = [
        f"Project: {p}",
        f"Type: {' + '.join(types) if types else 'unknown'}",
        "",
    ]

    if bloat:
        lines.append("Bloat found:")
        for name, size in sorted(bloat.items(), key=lambda x: -x[1]):
            lines.append(f"  {name:20} {human_size(size):>8}")
        lines.append("")
        lines.append(f"Total bloat: {human_size(total_bloat)}")
        lines.append(f"Tokens wasted: ~{tokens_wasted:,}")
    else:
        lines.append("No bloat detected. Project is clean.")

    lines.append("")

    if has_ignore and not fix:
        existing = claudeignore.read_text().count("\n")
        lines.append(f".claudeignore: exists ({existing} lines)")
    elif fix and patterns:
        # Generate .claudeignore
        content = [
            "# Auto-generated by @declutter",
            f"# Project type: {' + '.join(types) if types else 'unknown'}",
            f"# Estimated savings: ~{tokens_wasted:,} tokens",
            "",
        ]
        for pat in sorted(patterns):
            content.append(pat)

        claudeignore.write_text("\n".join(content) + "\n")
        lines.append(f".claudeignore: CREATED ({len(patterns)} patterns)")
        lines.append("Restart Claude for changes to take effect.")
    elif not has_ignore:
        lines.append(".claudeignore: missing")
        lines.append("Run with fix=True to create it.")

    return "\n".join(lines)


@mcp.tool()
def declutter(path: str = ".", fix: bool = False) -> str:
    """
    Scan project for bloat, estimate wasted tokens, optionally create .claudeignore.

    Examples:
      declutter()                    # scan current dir
      declutter("/path/to/project")  # scan specific path
      declutter(fix=True)            # scan + create .claudeignore

    Returns human-readable report with sizes, token estimates, and recommendations.
    """
    return run_declutter(path, fix)


if __name__ == "__main__":
    mcp.run()
